{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b2cae82-94fa-49a5-99ef-723006653268",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split, cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "095e926a-d035-4065-9e11-79fd7547b3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_team_features(df):\n",
    "    start_year = 24\n",
    "\n",
    "    # Create an empty list to hold DataFrames\n",
    "    all_stats = []\n",
    "    \n",
    "    for i in range(3):\n",
    "        year = start_year - i\n",
    "        season_str = f\"20{year-1}-20{year}\"\n",
    "        url_df = f'https://fbref.com/en/comps/Big5/{season_str}/{season_str}-Big-5-European-Leagues-Stats'\n",
    "    \n",
    "        try:\n",
    "            # Read all tables from the page\n",
    "            tables = pd.read_html(url_df)\n",
    "    \n",
    "            # Usually the first table contains the overall squad stats\n",
    "            temp = tables[0][['Squad', 'xG', 'xGA']]\n",
    "            temp['Season'] = season_str\n",
    "    \n",
    "            # Append to the list\n",
    "            all_stats.append(temp)\n",
    "    \n",
    "            #print(f\"Fetched {season_str} successfully.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to fetch {season_str}: {e}\")\n",
    "    \n",
    "    # combine\n",
    "    stats = pd.concat(all_stats, ignore_index=True)\n",
    "    df = df.merge(stats, on=['Squad', 'Season'], how='left')\n",
    "    return df\n",
    "\n",
    "def setup(df):\n",
    "    df = df.dropna(subset=['Rating'])\n",
    "    \n",
    "    df['Defensive_Efficiency'] = (df['Tkl'] + df['Blocks'] + df['Int']) / df['90s']\n",
    "    df['Offensive_Contribution'] = (df['Att 3rd'] + df['Crs'] + df['Sh']) / df['90s']\n",
    "    df['Tactical_Contribution'] = df['TklW'] + (df['Tkl%'] * df['Tkl'])\n",
    "    df['Penalty_Risk'] = (df['CrdY'] + df['CrdR'] + df['PKcon']) / df['90s']\n",
    "    df['Defensive_Interaction'] = df['Tkl'] + df['Blocks'] + df['Int']\n",
    "    #df['Seasonal_Trend'] = df.groupby('Season')['Rating'].transform(lambda x: x.diff()).fillna(0)\n",
    "    df['Win_Ratio'] = df['Won'] / (df['Won'] + df['Lost'])\n",
    "    \n",
    "    # Initialize 'Adjusted Rating' as a copy of 'Rating' to prevent NaNs for non-defenders\n",
    "    df['Adjusted Rating'] = df['Rating']\n",
    "    \n",
    "    # Calculate mean and standard deviation for defenders only\n",
    "    mean_rating = df[df['Pos'] == 'DF']['Rating'].mean()\n",
    "    std_rating = df[df['Pos'] == 'DF']['Rating'].std()\n",
    "    \n",
    "    # Calculate z-scores for defenders only\n",
    "    z_ratings = (df[df['Pos'] == 'DF']['Rating'] - mean_rating) / std_rating\n",
    "    \n",
    "    # Increase variance by scaling z-scores (factor > 1)\n",
    "    scaling_factor = 1.3  # Adjust the factor based on how much you want to increase the variance\n",
    "    scaled_z_ratings = z_ratings * scaling_factor\n",
    "    \n",
    "    # Revert to the original scale with increased variance for defenders only\n",
    "    df.loc[df['Pos'] == 'DF', 'Adjusted Rating'] = mean_rating + scaled_z_ratings * std_rating\n",
    "\n",
    "    orig_df = df.copy()\n",
    "    \n",
    "    #df = df[df['Pos'].str.contains(\"DF\", na=False)]\n",
    "    df = df.drop(columns=['Player Name'], errors=\"ignore\")  # Remove identifier column\n",
    "    \n",
    "    df = df.drop(columns=['Squad'])\n",
    "    \n",
    "    # One-hot encode categorical columns\n",
    "    categorical_cols = ['League', 'Season', 'Pos']\n",
    "    df = pd.get_dummies(df, columns=categorical_cols)\n",
    "    \n",
    "    # Fill missing values\n",
    "    df = df.fillna(df.median())\n",
    "    \n",
    "    #df = pd.get_dummies(df, columns=['Pos'], drop_first=True)\n",
    "    \n",
    "    # Drop Season columns if needed\n",
    "    #df = df.drop(df.filter(like=\"Season\").columns, axis=1)\n",
    "    #df = df.drop(df.filter(like=\"Squad\").columns, axis=1)\n",
    "    #df = df.drop(df.filter(like=\"League\").columns, axis=1)\n",
    "    \n",
    "    # Split data into features (X) and target (y)\n",
    "    return df, orig_df, mean_rating, std_rating\n",
    "\n",
    "# Define Optuna objective function\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000, step=100),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2, log=True),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-3, 10.0, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-3, 10.0, log=True),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10)\n",
    "    }\n",
    "\n",
    "    # Train model\n",
    "    model = xgb.XGBRegressor(**params, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Validate performance\n",
    "    y_pred = model.predict(X_val)\n",
    "    return r2_score(y_val, y_pred)\n",
    "\n",
    "# Run Optuna optimization\n",
    "def run_study(X_train, y_train, X_test, y_test, num_trials = 20):\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=num_trials)\n",
    "    \n",
    "    # Print best parameters\n",
    "    best_params = study.best_params\n",
    "    print(\"Best Hyperparameters:\", best_params)\n",
    "    \n",
    "    # Train final model with best parameters\n",
    "    best_model = xgb.XGBRegressor(**best_params, random_state=42)\n",
    "    best_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate performance on test set\n",
    "    y_pred_test = best_model.predict(X_test)\n",
    "    final_r2 = r2_score(y_test, y_pred_test)\n",
    "    final_mae = mean_absolute_error(y_test, y_pred_test)\n",
    "    \n",
    "    print(f\"Final R² Score: {final_r2:.4f}\")\n",
    "    print(f\"Final MAE: {final_mae:.4f}\")\n",
    "\n",
    "    return best_params\n",
    "\n",
    "# Cross Validation\n",
    "def cross_val(best_params, X_train, y_train, X_test, y_test):\n",
    "    # model with best hyperparameters, found from Optuna\n",
    "    best_model = xgb.XGBRegressor(**best_params, random_state=42)\n",
    "\n",
    "    best_model.fit(X_train, y_train)\n",
    "    \n",
    "    # cross-validation (function imported from sklearn.model_selection)\n",
    "    cv_results = cross_validate(best_model, X_test, y_test, cv=5, scoring=('r2', 'neg_mean_absolute_error'))\n",
    "    \n",
    "    # Print cross-validation results\n",
    "    print(\"Cross-validation R² scores:\", cv_results['test_r2'])\n",
    "    print(\"Cross-validation MAE scores:\", -cv_results['test_neg_mean_absolute_error'])  # MAE is negative due to how scoring works\n",
    "    \n",
    "    # Calculate the average R² score and MAE across folds\n",
    "    avg_r2 = cv_results['test_r2'].mean()\n",
    "    avg_mae = -cv_results['test_neg_mean_absolute_error'].mean()  # Negative to positive conversion for MAE\n",
    "    \n",
    "    print(f\"Average Cross-Validation R² Score: {avg_r2:.4f}\")\n",
    "    print(f\"Average Cross-Validation MAE: {avg_mae:.4f}\")\n",
    "\n",
    "def undo_adjusted_rating(y_adjusted, mean_rating, std_rating, scaling_factor=1.3):\n",
    "    unscaled_z = ((y_adjusted - mean_rating) / std_rating) / scaling_factor\n",
    "    return mean_rating + unscaled_z * std_rating\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb05316a-f6cf-4666-a48a-8bf60ef0c93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "    \"max_depth\": 3,\n",
    "    \"learning_rate\": 0.0605487138909333,\n",
    "    \"subsample\": 0.6177495307302218,\n",
    "    \"colsample_bytree\": 0.6524095821589513,\n",
    "    \"reg_alpha\": 0.6304827381123799,\n",
    "    \"reg_lambda\": 0.023966067481592194,\n",
    "    \"min_child_weight\": 8,\n",
    "    \"seed\": 42\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d3e4f35-7035-491d-a98a-ed1902c2a301",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\qrJos\\AppData\\Local\\Temp\\ipykernel_15324\\2728640446.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['Season'] = season_str\n",
      "C:\\Users\\qrJos\\AppData\\Local\\Temp\\ipykernel_15324\\2728640446.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['Season'] = season_str\n",
      "C:\\Users\\qrJos\\AppData\\Local\\Temp\\ipykernel_15324\\2728640446.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['Season'] = season_str\n",
      "C:\\Users\\qrJos\\AppData\\Local\\Temp\\ipykernel_15324\\2728640446.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Defensive_Efficiency'] = (df['Tkl'] + df['Blocks'] + df['Int']) / df['90s']\n",
      "C:\\Users\\qrJos\\AppData\\Local\\Temp\\ipykernel_15324\\2728640446.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Offensive_Contribution'] = (df['Att 3rd'] + df['Crs'] + df['Sh']) / df['90s']\n",
      "C:\\Users\\qrJos\\AppData\\Local\\Temp\\ipykernel_15324\\2728640446.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Tactical_Contribution'] = df['TklW'] + (df['Tkl%'] * df['Tkl'])\n",
      "C:\\Users\\qrJos\\AppData\\Local\\Temp\\ipykernel_15324\\2728640446.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Penalty_Risk'] = (df['CrdY'] + df['CrdR'] + df['PKcon']) / df['90s']\n",
      "C:\\Users\\qrJos\\AppData\\Local\\Temp\\ipykernel_15324\\2728640446.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Defensive_Interaction'] = df['Tkl'] + df['Blocks'] + df['Int']\n",
      "C:\\Users\\qrJos\\AppData\\Local\\Temp\\ipykernel_15324\\2728640446.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Win_Ratio'] = df['Won'] / (df['Won'] + df['Lost'])\n",
      "C:\\Users\\qrJos\\AppData\\Local\\Temp\\ipykernel_15324\\2728640446.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Adjusted Rating'] = df['Rating']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation R² scores: [0.59158718 0.65086582 0.54119213 0.63298963 0.56311021]\n",
      "Cross-validation MAE scores: [0.11222479 0.11678867 0.11081823 0.11104977 0.12213882]\n",
      "Average Cross-Validation R² Score: 0.5959\n",
      "Average Cross-Validation MAE: 0.1146\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"finalized_players.csv\")\n",
    "df = add_team_features(df)\n",
    "df, orig_df, mean_def, std_def = setup(df)\n",
    "\n",
    "#X = df.drop(columns=['Rating', 'Adjusted Rating'], errors=\"ignore\")\n",
    "#y = df['Adjusted Rating']\n",
    "#X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "#X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "df_2021_2023 = df[df['Season_2021-2022'] | df['Season_2022-2023']].drop(columns=['Season_2021-2022', 'Season_2022-2023', 'Season_2023-2024'])\n",
    "df_2024 = df[df['Season_2023-2024']].drop(columns=['Season_2021-2022', 'Season_2022-2023', 'Season_2023-2024'])\n",
    "X_train = df_2021_2023.drop(columns=['Rating', 'Adjusted Rating'], errors=\"ignore\")\n",
    "y_train = df_2021_2023['Rating']\n",
    "X_test = df_2024.drop(columns=['Rating', 'Adjusted Rating'], errors=\"ignore\")\n",
    "y_test = df_2024['Rating']\n",
    "\n",
    "#best_params = run_study(X_train, y_train, X_test, y_test, 5)\n",
    "\n",
    "cross_val(best_params, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cd36dc-b8b8-414d-b04a-77ba1bf80b9c",
   "metadata": {},
   "source": [
    "Why is this Rsq so high? I think there's overfitting (as this accuracy should be *worse* than descriptive, given there's no stats measuring change with time and yet the Rsq is 0.5949). I won't report this number in the presentation (it was naive of me to do that before every time I saw a higher Rsq without checking if it was validly found). Note that the descriptive Rsq was only 0.51. These are also the exact same parameters that came from the descriptive model, I just refit the model in the cross validation function on exclusively the training data (the 2 seasons from 2021-2023), and did cross validation on exclusively the test data (the single 2023-2024 season). I will mention briefly to Tad if I have time.\n",
    "\n",
    "Also note that Rsq when predicting adjusted rating (increased variance to match offensive) and actual rating (no increased variance in the assumed normal distribution) was almost the same (0.5949 for Adjusted, 0.5959 for non-Adjusted), even though in other testing, adjusted rating tended to be easier to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a16cdaba-2c1f-47d9-b403-8f6ca47bd604",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBRegressor(**best_params, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "#df['Predicted Adjusted Rating'] = y_pred\n",
    "#df = df[[col for col in df.columns if col != 'Rating'] + ['Rating']]\n",
    "#df = df[[col for col in df.columns if col != 'Adjusted Rating'] + ['Adjusted Rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22bf7964-5ead-45ef-b450-c680a7da25c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6024609225335877"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(y_test, y_test_pred)\n",
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d645e29-c59e-428f-b265-d009ab06ede7",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_2024 = orig_df[orig_df['Season'] == '2023-2024'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1478fb6d-2128-492d-9798-a5524750f716",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_2024['Predicted Rating'] = y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3167015b-8d9b-4bf4-ad1a-f4ec6c4176ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_2024.to_csv('pred_2024_no_bias.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d29e0807-4b82-4f42-88fe-fc8e5e03dff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['90s', 'Tkl', 'TklW', 'Def 3rd', 'Mid 3rd', 'Att 3rd', 'Chl-Tkl', 'Att',\n",
       "       'Tkl%', 'Chl-Lost', 'Blocks', 'Sh', 'Pass', 'Int', 'Tkl+Int', 'Clr',\n",
       "       'Err', 'CrdY', 'CrdR', '2CrdY', 'Fls', 'Off', 'Crs', 'PKcon', 'OG',\n",
       "       'Recov', 'Won', 'Lost', 'Won%', 'Rating', 'xG', 'xGA',\n",
       "       'Defensive_Efficiency', 'Offensive_Contribution',\n",
       "       'Tactical_Contribution', 'Penalty_Risk', 'Defensive_Interaction',\n",
       "       'Win_Ratio', 'Adjusted Rating', 'League_Bundesliga', 'League_La Liga',\n",
       "       'League_Ligue 1', 'League_Premier League', 'League_Serie A',\n",
       "       'Season_2021-2022', 'Season_2022-2023', 'Season_2023-2024', 'Pos_DF',\n",
       "       'Pos_DF,MF', 'Pos_MF', 'Pos_MF,DF'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55d5813d-0ba1-4646-9a28-55e14eb6b2ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'objective': 'reg:squarederror', 'base_score': None, 'booster': None, 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': 0.6524095821589513, 'device': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': 0.0605487138909333, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': 3, 'max_leaves': None, 'min_child_weight': 8, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': None, 'n_jobs': None, 'num_parallel_tree': None, 'random_state': 42, 'reg_alpha': 0.6304827381123799, 'reg_lambda': 0.023966067481592194, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': 0.6177495307302218, 'tree_method': None, 'validate_parameters': None, 'verbosity': None, 'seed': 42}\n"
     ]
    }
   ],
   "source": [
    "params = model.get_params()\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37b9e495-7cb2-49bb-ad25-d068e1e79e84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nscaled_mask = df['Adjusted Rating'] != df['Rating']\\n\\n# Create new column: Predicted Actual Rating\\n#df['Predicted Rating'] = df['Predicted Adjusted Rating']  # Default for non-defenders\\n\\n# Undo scaling only for defenders\\n#df.loc[scaled_mask, 'Predicted Rating'] = undo_adjusted_rating(\\n#    df.loc[scaled_mask, 'Predicted Adjusted Rating'],\\n#    mean_rating=mean_def,\\n#    std_rating=std_def,\\n#    scaling_factor=1.3  # or whatever factor you used\\n#)\\n\\n# Undo One-Hot Encoding\\ndf['Player Name'] = orig_df['Player Name']\\npred_df = df\\n\\ndf['Squad'] = orig_df['Squad']\\ndf['League'] = orig_df['League']\\n\\ndf.to_csv('messy.csv', index=False)\\n\\n# Restore League\\nleague_cols = [col for col in df.columns if col.startswith('League_')]\\ndf['League'] = df[league_cols].idxmax(axis=1).str.replace('League_', '', regex=False)\\n\\n# Restore Season\\nseason_cols = [col for col in df.columns if col.startswith('Season_')]\\ndf['Season'] = df[season_cols].idxmax(axis=1).str.replace('Season_', '', regex=False)\\n\\n# Restore Position\\npos_cols = [col for col in df.columns if col.startswith('Pos_')]\\ndf['Pos'] = df[pos_cols].idxmax(axis=1).str.replace('Pos_', '', regex=False)\\n\\n# Drop one-hot encoded columns\\ndf = df.drop(columns=league_cols + season_cols + pos_cols)\\n\\n# Round rating columns\\nrating_cols = ['Adjusted Rating', 'Rating', 'Predicted Rating']\\ndf[rating_cols] = df[rating_cols].round(2)\\n\\n# Reorder columns: start with key identifiers, end with ratings\\nkey_cols = ['Player Name', 'Pos', 'Squad', 'League', 'Season']\\nother_cols = [col for col in df.columns if col not in key_cols + rating_cols]\\ndf = df[key_cols + other_cols + rating_cols]\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra work only used for descriptive\n",
    "\"\"\"\n",
    "scaled_mask = df['Adjusted Rating'] != df['Rating']\n",
    "\n",
    "# Create new column: Predicted Actual Rating\n",
    "#df['Predicted Rating'] = df['Predicted Adjusted Rating']  # Default for non-defenders\n",
    "\n",
    "# Undo scaling only for defenders\n",
    "#df.loc[scaled_mask, 'Predicted Rating'] = undo_adjusted_rating(\n",
    "#    df.loc[scaled_mask, 'Predicted Adjusted Rating'],\n",
    "#    mean_rating=mean_def,\n",
    "#    std_rating=std_def,\n",
    "#    scaling_factor=1.3  # or whatever factor you used\n",
    "#)\n",
    "\n",
    "# Undo One-Hot Encoding\n",
    "df['Player Name'] = orig_df['Player Name']\n",
    "pred_df = df\n",
    "\n",
    "df['Squad'] = orig_df['Squad']\n",
    "df['League'] = orig_df['League']\n",
    "\n",
    "df.to_csv('messy.csv', index=False)\n",
    "\n",
    "# Restore League\n",
    "league_cols = [col for col in df.columns if col.startswith('League_')]\n",
    "df['League'] = df[league_cols].idxmax(axis=1).str.replace('League_', '', regex=False)\n",
    "\n",
    "# Restore Season\n",
    "season_cols = [col for col in df.columns if col.startswith('Season_')]\n",
    "df['Season'] = df[season_cols].idxmax(axis=1).str.replace('Season_', '', regex=False)\n",
    "\n",
    "# Restore Position\n",
    "pos_cols = [col for col in df.columns if col.startswith('Pos_')]\n",
    "df['Pos'] = df[pos_cols].idxmax(axis=1).str.replace('Pos_', '', regex=False)\n",
    "\n",
    "# Drop one-hot encoded columns\n",
    "df = df.drop(columns=league_cols + season_cols + pos_cols)\n",
    "\n",
    "# Round rating columns\n",
    "rating_cols = ['Adjusted Rating', 'Rating', 'Predicted Rating']\n",
    "df[rating_cols] = df[rating_cols].round(2)\n",
    "\n",
    "# Reorder columns: start with key identifiers, end with ratings\n",
    "key_cols = ['Player Name', 'Pos', 'Squad', 'League', 'Season']\n",
    "other_cols = [col for col in df.columns if col not in key_cols + rating_cols]\n",
    "df = df[key_cols + other_cols + rating_cols]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7edf1573-a5a7-4e5a-9df1-4b9a3602836f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "721a223e-e907-478f-93e2-0b74133ff12f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntrain = pred_df.dropna(subset=['Rating Diff'])\\ntest = pred_df[pred_df['Rating Diff'].isnull()]\\nX_train = train.drop(columns=['Rating Diff', 'Player Name', 'Next_Rating', 'Next_Season', 'Pos', 'Squad', 'League', 'Season'])\\ny_train = train['Rating Diff']\\n\\nmodel.fit(X_train, y_train)\\ny_pred = model.predict(X_test)\\n\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# experimental \"rating difference\" usage that didn't work out well/help at all\n",
    "\"\"\"\n",
    "train = pred_df.dropna(subset=['Rating Diff'])\n",
    "test = pred_df[pred_df['Rating Diff'].isnull()]\n",
    "X_train = train.drop(columns=['Rating Diff', 'Player Name', 'Next_Rating', 'Next_Season', 'Pos', 'Squad', 'League', 'Season'])\n",
    "y_train = train['Rating Diff']\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6dd20586-67c9-4c2d-84b8-835e4b1fc0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c13ef80-8e1b-4e24-a594-721fa7c0d1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test = X_test.drop(columns=['Season_2021-2022', 'Season_2022-2023', 'Season_2023-2024', 'Pos_DF', 'Pos_DF,MF', 'Pos_MF', 'Pos_MF,DF', 'League_Bundesliga', 'League_La Liga', 'League_Ligue 1', 'League_Premier League', 'League_Serie A'], errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2026c6a-a1b8-409d-b47d-f004c6e92594",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6f65593-f70b-4561-a648-41446a10a102",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.read_html('https://fbref.com/en/comps/Big5/2023-2024/2023-2024-Big-5-European-Leagues-Stats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2158aa21-759c-492d-9887-c2e5f46c376f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from descriptive model\n",
    "best_params = {\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "    \"max_depth\": 3,\n",
    "    \"learning_rate\": 0.0605487138909333,\n",
    "    \"subsample\": 0.6177495307302218,\n",
    "    \"colsample_bytree\": 0.6524095821589513,\n",
    "    \"reg_alpha\": 0.6304827381123799,\n",
    "    \"reg_lambda\": 0.023966067481592194,\n",
    "    \"min_child_weight\": 8,\n",
    "    \"seed\": 42\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15d07360-6b2a-4613-a5fd-0fdad8b5f0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
